{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import os, re, operator, warnings\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION,p.OPT.RESERVED,p.OPT.SMILEY,p.OPT.NUMBER) # Setting paramenter to only remove the mentioned from the tweet\n",
    "from unicodedata import normalize\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "\n",
    "def words_tokenizer(data):\n",
    "    tknzr = TweetTokenizer()\n",
    "    words = tknzr.tokenize(data)\n",
    "    return words\n",
    "\n",
    "def preprocessing_pipeline(tweet,bigrams=True):\n",
    "    tweet = p.clean(tweet) # Python tweet preprocessor to remove URL, Mention, Hashtag, Reserved Words, Emoji, Smiley\n",
    "    tweet = tweet.lstrip(\"b'\").rstrip(\"''\") # Removing 'b' character and the single quotes from the tweet\n",
    "    tweet = re.sub(r'\\\\\\S+', '', tweet) # Replace all character starting with '\\' till space\n",
    "    tweet = re.sub(r'([^\\w\\s])|_+', ' ', tweet) # Removing punctuations\n",
    "#     tweet = re.sub('['+my_punctuation + ']+', '', tweet) # strip punctuation\n",
    "    tweet = re.sub(r'(\\s\\S{1,2}$)|(\\s\\S{1,2}\\s$)','',tweet) # Removing the residual words at the end of the sentence with at most 2 characters\n",
    "    tweet = re.sub(r'^\\s','',tweet) # Removing whitespace from the start of the tweet\n",
    "    tweet = re.sub(r'\\s$','',tweet) # Removing whitespace from the end of the tweet\n",
    "    tweet = re.sub(r'\\s\\s+',' ',tweet) # Removing extra space throughout\n",
    "    tweet = tweet.lower() # Lower-casing the text\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "\n",
    "#     tweet_token_list = [word_rooter(word) if '#' not in word else word\n",
    "#                         for word in tweet_token_list] # apply word rooter\n",
    "#     if bigrams:\n",
    "#         tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "#                                             for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet\n",
    "\n",
    "def spacy_prepro(doc):\n",
    "    # we add some words to the stop word list\n",
    "    article = []\n",
    "    for w in doc:\n",
    "        # if it's not a stop word or punctuation mark, add it to our article!\n",
    "        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num and w.text!=' ' and w.text not in article:\n",
    "            # we add the lematized version of the word\n",
    "            article.append(w.lemma_)\n",
    "    return article\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'LIAR-PLUS/dataset/train2.tsv'\n",
    "filepath_test = 'LIAR-PLUS/dataset/test2.tsv'\n",
    "filepath_val = 'LIAR-PLUS/dataset/val2.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath, usecols=[2,3,9,10,11,12,13,15], names=['label', 'statement','barely_true_count','false_count','half_true_count','mostly_true_count','pof_count','justification'], header=None, delimiter='\\t')\n",
    "df_test = pd.read_csv(filepath_test, usecols=[2,3,9,10,11,12,13,15], names=['label', 'statement','barely_true_count','false_count','half_true_count','mostly_true_count','pof_count','justification'], header=None, delimiter='\\t')\n",
    "df_val = pd.read_csv(filepath_val, usecols=[2,3,9,10,11,12,13,15], names=['label', 'statement','barely_true_count','false_count','half_true_count','mostly_true_count','pof_count','justification'], header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = ['half-true', 'mostly true', 'true']\n",
    "false_labels = ['pants on fire', 'false', 'mostly false']\n",
    "\n",
    "train_labels_multi = df['label']\n",
    "train_labels_binary = []\n",
    "for i in range(len(train_labels_multi)):\n",
    "    if train_labels_multi[i] in true_labels:\n",
    "        train_labels_binary.append('true')\n",
    "    else:\n",
    "        train_labels_binary.append('false')\n",
    "        \n",
    "test_labels_multi = df_test['label']\n",
    "test_labels_binary = []\n",
    "for i in range(len(test_labels_multi)):\n",
    "    if test_labels_multi[i] in true_labels:\n",
    "        test_labels_binary.append('true')\n",
    "    else:\n",
    "        test_labels_binary.append('false')\n",
    "\n",
    "val_labels_multi = df_val['label']\n",
    "val_labels_binary = []\n",
    "for i in range(len(val_labels_multi)):\n",
    "    if val_labels_multi[i] in true_labels:\n",
    "        val_labels_binary.append('true')\n",
    "    else:\n",
    "        val_labels_binary.append('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_blabels_df = pd.DataFrame(train_labels_binary)\n",
    "train_blabels_df.columns = [\"label\"]\n",
    "\n",
    "test_blabels_df = pd.DataFrame(test_labels_binary)\n",
    "test_blabels_df.columns = [\"label\"]\n",
    "\n",
    "val_blabels_df = pd.DataFrame(val_labels_binary)\n",
    "val_blabels_df.columns = [\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10240/10240 [01:25<00:00, 120.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_processed_S = []\n",
    "for i in tqdm(range(len(df['statement']))):\n",
    "    a = preprocessing_pipeline(df['statement'][i])\n",
    "    b = ' '.join(spacy_prepro(nlp(a)))\n",
    "    train_processed_S.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1267/1267 [00:09<00:00, 134.21it/s]\n"
     ]
    }
   ],
   "source": [
    "test_processed_S = []\n",
    "for i in tqdm(range(len(df_test['statement']))):\n",
    "    a = preprocessing_pipeline(df_test['statement'][i])\n",
    "    b = ' '.join(spacy_prepro(nlp(a)))\n",
    "    test_processed_S.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1284/1284 [00:09<00:00, 133.21it/s]\n"
     ]
    }
   ],
   "source": [
    "val_processed_S = []\n",
    "for i in tqdm(range(len(df_val['statement']))):\n",
    "    a = preprocessing_pipeline(df_val['statement'][i])\n",
    "    b = ' '.join(spacy_prepro(nlp(a)))\n",
    "    val_processed_S.append(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "> Validation coming better on unigram, test better on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "# vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,min_df = 2, ngram_range=(1,2)) # ngram_range = unigram and bigrams\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "X_train_S = vectorizer.fit_transform(train_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_S) \n",
    "# X_train_S = tf_transformer.transform(X_train_S)\n",
    "\n",
    "X_test_S = vectorizer.transform(test_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_S) \n",
    "# X_test_S = tf_transformer.transform(X_test_S)\n",
    "\n",
    "X_val_S = vectorizer.transform(val_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_val_S) \n",
    "# X_val_S = tf_transformer.transform(X_val_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LinearSVC(random_state=0, tol=1e-5)\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "# clf = GridSearchCV(model, parameters, cv=5)\n",
    "model.fit(X_train_S,train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "predicted =model.predict(X_test_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5659037095501184\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "predicted_val_S =model.predict(X_val_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6160436137071651\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted_val_S[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted_val_S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "\n",
    "> Giving better results on unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_S = vectorizer.fit_transform(train_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_S) \n",
    "# X_train_S = tf_transformer.transform(X_train_S)\n",
    "\n",
    "X_test_S = vectorizer.transform(test_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_S) \n",
    "# X_test_S = tf_transformer.transform(X_test_S)\n",
    "\n",
    "X_val_S = vectorizer.transform(val_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_val_S) \n",
    "# X_val_S = tf_transformer.transform(X_val_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(random_state=0, tol=1e-5)\n",
    "model.fit(X_train_S,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23046566692975531\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "\n",
    "predicted =model.predict(X_test_S)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2398753894080997\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "\n",
    "predicted_val_S =model.predict(X_val_S)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted_val_S[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted_val_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Combining train and validation\n",
    "\n",
    "# train_val_processed_S = train_processed_S + val_processed_S\n",
    "# a = list(df['label'])\n",
    "# b = list(df_val['label'])\n",
    "# c = np.array(a+b)\n",
    "\n",
    "# X_train_val_S = vectorizer.fit_transform(train_val_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_val_S) \n",
    "# X_train_val_S = tf_transformer.transform(X_train_val_S)\n",
    "\n",
    "# X_test_S = vectorizer.transform(test_processed_S)\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_S) \n",
    "# X_test_S = tf_transformer.transform(X_test_S)\n",
    "\n",
    "# model = LinearSVC(random_state=0, tol=1e-5)\n",
    "# model.fit(X_train_val_S,c)\n",
    "\n",
    "# count=0\n",
    "# for i in range(len(df_test['label'])):\n",
    "#     if df_test['label'][i]==predicted[i]:\n",
    "#         count+=1\n",
    "# print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr').fit(X_train_S, train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5911602209944752\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_S)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6347352024922118\n"
     ]
    }
   ],
   "source": [
    "predicted_val_S =clf.predict(X_val_S)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted_val_S[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted_val_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train_S, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23362273086029992\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_S)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2383177570093458\n"
     ]
    }
   ],
   "source": [
    "predicted_val_S =clf.predict(X_val_S)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted_val_S[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted_val_S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SJ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10240/10240 [02:03<00:00, 82.95it/s]\n"
     ]
    }
   ],
   "source": [
    "train_processed_J = []\n",
    "for i in tqdm(range(len(df['justification']))):\n",
    "    try:\n",
    "        a = preprocessing_pipeline(df['justification'][i])\n",
    "        b = ' '.join(spacy_prepro(nlp(a)))\n",
    "        train_processed_J.append(b)\n",
    "    except:\n",
    "        train_processed_J.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1267/1267 [00:15<00:00, 82.09it/s]\n"
     ]
    }
   ],
   "source": [
    "test_processed_J = []\n",
    "for i in tqdm(range(len(df_test['justification']))):\n",
    "    try:\n",
    "        a = preprocessing_pipeline(df_test['justification'][i])\n",
    "        b = ' '.join(spacy_prepro(nlp(a)))\n",
    "        test_processed_J.append(b)\n",
    "    except:\n",
    "        test_processed_J.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1284/1284 [00:15<00:00, 84.76it/s]\n"
     ]
    }
   ],
   "source": [
    "val_processed_J = []\n",
    "for i in tqdm(range(len(df_val['justification']))):\n",
    "    try:\n",
    "        a = preprocessing_pipeline(df_val['justification'][i])\n",
    "        b = ' '.join(spacy_prepro(nlp(a)))\n",
    "        val_processed_J.append(b)\n",
    "    except:\n",
    "        val_processed_J.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_SJ = []\n",
    "for i in range(len(train_processed_S)):\n",
    "    temp = train_processed_S[i]+\" \"+train_processed_J[i]\n",
    "    train_processed_SJ.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed_SJ = []\n",
    "for i in range(len(test_processed_S)):\n",
    "    temp = test_processed_S[i]+\" \"+test_processed_J[i]\n",
    "    test_processed_SJ.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_processed_SJ = []\n",
    "for i in range(len(val_processed_S)):\n",
    "    temp = val_processed_S[i]+\" \"+val_processed_J[i]\n",
    "    val_processed_SJ.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,min_df = 2, ngram_range=(1,2)) # ngram_range = unigram and bigrams\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_SJ = vectorizer.fit_transform(train_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_SJ) \n",
    "X_train_SJ = tf_transformer.transform(X_train_SJ)\n",
    "\n",
    "X_test_SJ = vectorizer.transform(test_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_SJ) \n",
    "X_test_SJ = tf_transformer.transform(X_test_SJ)\n",
    "\n",
    "X_val_SJ = vectorizer.transform(val_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_val_SJ) \n",
    "X_val_SJ = tf_transformer.transform(X_val_SJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "model_LSVC.fit(X_train_SJ,train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5808997632202052\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_test_SJ)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6105919003115264\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_val_SJ)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "#     print(df_val['label'][i],predicted[i])\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr').fit(X_train_SJ, train_blabels_df['label'])\n",
    "# clf = LogisticRegression().fit(X,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235201262825573\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_SJ)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6651090342679128\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_val_SJ)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,min_df = 2, ngram_range=(1,2)) # ngram_range = unigram and bigrams\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_SJ = vectorizer.fit_transform(train_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_SJ) \n",
    "X_train_SJ = tf_transformer.transform(X_train_SJ)\n",
    "\n",
    "X_test_SJ = vectorizer.transform(test_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_SJ) \n",
    "X_test_SJ = tf_transformer.transform(X_test_SJ)\n",
    "\n",
    "X_val_SJ = vectorizer.transform(val_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_val_SJ) \n",
    "X_val_SJ = tf_transformer.transform(X_val_SJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "model_LSVC.fit(X_train_SJ,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21783741120757696\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_test_SJ)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21339563862928349\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_val_SJ)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "#     print(df_val['label'][i],predicted[i])\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train_SJ, df['label'])\n",
    "# clf = LogisticRegression().fit(X,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23441199684293607\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_SJ)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24221183800623053\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_val_SJ)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S+M and S+MJ\n",
    "\n",
    "> Only the vectorizer valued is changed for M and MJ dataset, rest remains same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n",
    "\n",
    "> Senti Strength with binary positivity and negativity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentistrength import PySentiStr\n",
    "\n",
    "# senti = PySentiStr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# senti.setSentiStrengthPath('/home/shreyash15097/my/SentiStrength/SentiStrength.jar')\n",
    "# senti.setSentiStrengthLanguageFolderPath('/home/shreyash15097/my/SentiStrength/SentiStrengthData/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_senti = []\n",
    "# for i in tqdm(range(len(train_processed_S))):\n",
    "#     result = senti.getSentiment(train_processed_S[i], score='binary')\n",
    "#     train_senti.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_senti = []\n",
    "# for i in tqdm(range(len(test_processed_S))):\n",
    "#     result = senti.getSentiment(test_processed_S[i], score='binary')\n",
    "#     test_senti.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val_senti = []\n",
    "# for i in tqdm(range(len(df_val['statement']))):\n",
    "#     result = senti.getSentiment(df_val['statement'][i], score='binary')\n",
    "#     val_senti.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "senti_train = {}\n",
    "with open('train_senti.pkl','rb') as f:\n",
    "    senti_train = pickle.load(f)\n",
    "\n",
    "senti_test = {}\n",
    "with open('test_senti.pkl','rb') as f:\n",
    "    senti_test = pickle.load(f)\n",
    "\n",
    "senti_val = {}\n",
    "with open('val_senti.pkl','rb') as f:\n",
    "    senti_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = []\n",
    "neg_sent = []\n",
    "for i in range(len(senti_train)):\n",
    "    ps = senti_train[i][0][0]\n",
    "    ns = senti_train[i][0][1]\n",
    "    pos_sent.append(ps)\n",
    "    neg_sent.append(abs(ns))\n",
    "senti_train_df = pd.DataFrame(pos_sent,columns =['pos_sent']) \n",
    "senti_train_df['neg_sent'] = neg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = []\n",
    "neg_sent = []\n",
    "for i in range(len(senti_test)):\n",
    "    ps = senti_test[i][0][0]\n",
    "    ns = senti_test[i][0][1]\n",
    "    pos_sent.append(ps)\n",
    "    neg_sent.append(abs(ns))\n",
    "senti_test_df = pd.DataFrame(pos_sent,columns =['pos_sent']) \n",
    "senti_test_df['neg_sent'] = neg_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = []\n",
    "neg_sent = []\n",
    "for i in range(len(senti_val)):\n",
    "    ps = senti_val[i][0][0]\n",
    "    ns = senti_val[i][0][1]\n",
    "    pos_sent.append(ps)\n",
    "    neg_sent.append(abs(ns))\n",
    "senti_val_df = pd.DataFrame(pos_sent,columns =['pos_sent']) \n",
    "senti_val_df['neg_sent'] = neg_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lexicon = pd.read_csv('/home/shreyash15097/fnd/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', usecols=[0,1,2], names=['word','emotion','value'], header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_dic = {}\n",
    "for i in range(len(df_lexicon)):\n",
    "    word = df_lexicon['word'][i]\n",
    "    emotion = df_lexicon['emotion'][i]\n",
    "    value = df_lexicon['value'][i]\n",
    "    if word not in emolex_dic:\n",
    "        emolex_dic[word] = {}\n",
    "    emolex_dic[word][emotion] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_train = []\n",
    "for i in range(len(df['statement'])):\n",
    "    temp = df['statement'][i].lower().split()\n",
    "    temp2 = np.zeros(10,dtype=int)\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in emolex_dic:\n",
    "            temp2 += np.array(list(emolex_dic[temp[j]].values()))\n",
    "    emolex_train.append(list(temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_test = []\n",
    "for i in range(len(df_test['statement'])):\n",
    "    temp = df_test['statement'][i].lower().split()\n",
    "    temp2 = np.zeros(10,dtype=int)\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in emolex_dic:\n",
    "            temp2 += np.array(list(emolex_dic[temp[j]].values()))\n",
    "    emolex_test.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_val = []\n",
    "for i in range(len(df_val['statement'])):\n",
    "    temp = df_val['statement'][i].lower().split()\n",
    "    temp2 = np.zeros(10,dtype=int)\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in emolex_dic:\n",
    "            temp2 += np.array(list(emolex_dic[temp[j]].values()))\n",
    "    emolex_val.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_train_df = pd.DataFrame(emolex_train)\n",
    "emolex_train_df.columns = [\"e1\", \"e2\", \"e3\", \"e4\", \"e5\", \"e6\", \"e7\", \"e8\", \"e9\", \"e10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_test_df = pd.DataFrame(emolex_test)\n",
    "emolex_test_df.columns = [\"e1\", \"e2\", \"e3\", \"e4\", \"e5\", \"e6\", \"e7\", \"e8\", \"e9\", \"e10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_val_df = pd.DataFrame(emolex_val)\n",
    "emolex_val_df.columns = [\"e1\", \"e2\", \"e3\", \"e4\", \"e5\", \"e6\", \"e7\", \"e8\", \"e9\", \"e10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "> That can be directly used from the original dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'statement', 'barely_true_count', 'false_count',\n",
       "       'half_true_count', 'mostly_true_count', 'pof_count', 'justification'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fixing nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df['barely_true_count'][2142] = 0.0\n",
    "df['false_count'][2142] = 0.0\n",
    "df['half_true_count'][2142] = 0.0\n",
    "df['mostly_true_count'][2142] = 0.0\n",
    "df['pof_count'][2142] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df['barely_true_count'][9375] = 0.0\n",
    "df['false_count'][9375] = 0.0\n",
    "df['half_true_count'][9375] = 0.0\n",
    "df['mostly_true_count'][9375] = 0.0\n",
    "df['pof_count'][9375] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truenan = np.isnan(df['pof_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(truenan)):\n",
    "#     if truenan[i]==True:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S+MJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,min_df = 2, ngram_range=(1,2)) # ngram_range = unigram and bigrams\n",
    "# vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SpMJ = vectorizer.fit_transform(train_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_SpMJ) \n",
    "X_train_SpMJ = tf_transformer.transform(X_train_SpMJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Adding rest of the features\n",
    "\n",
    "# Sentiment Features\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(senti_train_df['pos_sent'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(senti_train_df['neg_sent'])[:,None]))\n",
    "\n",
    "# Emolex features\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e1'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e2'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e3'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e4'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e5'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e6'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e7'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e8'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e9'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(emolex_train_df['e10'])[:,None]))\n",
    "\n",
    "# Metadata\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(df['barely_true_count'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(df['false_count'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(df['half_true_count'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(df['mostly_true_count'])[:,None]))\n",
    "X_train_SpMJ = hstack((X_train_SpMJ,np.array(df['pof_count'])[:,None]))\n",
    "print(np.isnan(X_train_SpMJ.data).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240, 62415)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_SpMJ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SpMJ = vectorizer.transform(test_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_SpMJ) \n",
    "X_test_SpMJ = tf_transformer.transform(X_test_SpMJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding rest of the features\n",
    "\n",
    "# Sentiment Features\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(senti_test_df['pos_sent'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(senti_test_df['neg_sent'])[:,None]))\n",
    "\n",
    "# Emolex features\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e1'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e2'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e3'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e4'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e5'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e6'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e7'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e8'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e9'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(emolex_test_df['e10'])[:,None]))\n",
    "\n",
    "# Metadata\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(df_test['barely_true_count'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(df_test['false_count'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(df_test['half_true_count'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(df_test['mostly_true_count'])[:,None]))\n",
    "X_test_SpMJ = hstack((X_test_SpMJ,np.array(df_test['pof_count'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267, 62415)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_SpMJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_SpMJ = vectorizer.transform(val_processed_SJ)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_val_SpMJ) \n",
    "X_val_SpMJ = tf_transformer.transform(X_val_SpMJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding rest of the features\n",
    "\n",
    "# Sentiment Features\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(senti_val_df['pos_sent'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(senti_val_df['neg_sent'])[:,None]))\n",
    "\n",
    "# Emolex features\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e1'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e2'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e3'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e4'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e5'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e6'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e7'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e8'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e9'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(emolex_val_df['e10'])[:,None]))\n",
    "\n",
    "# Metadata\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(df_val['barely_true_count'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(df_val['false_count'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(df_val['half_true_count'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(df_val['mostly_true_count'])[:,None]))\n",
    "X_val_SpMJ = hstack((X_val_SpMJ,np.array(df_val['pof_count'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 62415)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_SpMJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "model_LSVC.fit(X_train_SpMJ,train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5832675611681136\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_test_SpMJ)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6230529595015576\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_val_SpMJ)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regerssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr').fit(X_train_SpMJ, train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235201262825573\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_SpMJ)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677570093457944\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_val_SpMJ)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "model_LSVC.fit(X_train_SpMJ,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.250197316495659\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_test_SpMJ)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29127725856697817\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_val_SpMJ)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train_SpMJ, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.303078137332281\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_SpMJ)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3325545171339564\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_val_SpMJ)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S+M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer = None,preprocessor = None,min_df = 2, ngram_range=(1,2)) # ngram_range = unigram and bigrams\n",
    "# vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SpM = vectorizer.fit_transform(train_processed_S)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_SpM) \n",
    "X_train_SpM = tf_transformer.transform(X_train_SpM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Adding rest of the features\n",
    "\n",
    "# Sentiment Features\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(senti_train_df['pos_sent'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(senti_train_df['neg_sent'])[:,None]))\n",
    "\n",
    "# Emolex features\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e1'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e2'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e3'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e4'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e5'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e6'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e7'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e8'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e9'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(emolex_train_df['e10'])[:,None]))\n",
    "\n",
    "# Metadata\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(df['barely_true_count'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(df['false_count'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(df['half_true_count'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(df['mostly_true_count'])[:,None]))\n",
    "X_train_SpM = hstack((X_train_SpM,np.array(df['pof_count'])[:,None]))\n",
    "print(np.isnan(X_train_SpM.data).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SpM = vectorizer.transform(test_processed_S)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_test_SpM) \n",
    "X_test_SpM = tf_transformer.transform(X_test_SpM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding rest of the features\n",
    "\n",
    "# Sentiment Features\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(senti_test_df['pos_sent'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(senti_test_df['neg_sent'])[:,None]))\n",
    "\n",
    "# Emolex features\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e1'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e2'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e3'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e4'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e5'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e6'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e7'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e8'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e9'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(emolex_test_df['e10'])[:,None]))\n",
    "\n",
    "# Metadata\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(df_test['barely_true_count'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(df_test['false_count'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(df_test['half_true_count'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(df_test['mostly_true_count'])[:,None]))\n",
    "X_test_SpM = hstack((X_test_SpM,np.array(df_test['pof_count'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_SpM = vectorizer.transform(val_processed_S)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_val_SpM) \n",
    "X_val_SpM = tf_transformer.transform(X_val_SpM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding rest of the features\n",
    "\n",
    "# Sentiment Features\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(senti_val_df['pos_sent'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(senti_val_df['neg_sent'])[:,None]))\n",
    "\n",
    "# Emolex features\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e1'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e2'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e3'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e4'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e5'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e6'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e7'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e8'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e9'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(emolex_val_df['e10'])[:,None]))\n",
    "\n",
    "# Metadata\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(df_val['barely_true_count'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(df_val['false_count'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(df_val['half_true_count'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(df_val['mostly_true_count'])[:,None]))\n",
    "X_val_SpM = hstack((X_val_SpM,np.array(df_val['pof_count'])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "model_LSVC.fit(X_train_SpM,train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6093133385951065\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_test_SpM)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6347352024922118\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_val_SpM)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr').fit(X_train_SpM, train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235201262825573\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_SpM)\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752336448598131\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_val_SpM)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "model_LSVC.fit(X_train_SpM,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24230465666929754\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_test_SpM)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26557632398753894\n"
     ]
    }
   ],
   "source": [
    "predicted =model_LSVC.predict(X_val_SpM)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train_SpM, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2975532754538279\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_test_SpM)\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32087227414330216\n"
     ]
    }
   ],
   "source": [
    "predicted =clf.predict(X_val_SpM)\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier - Nueral Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpMJ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,), random_state=1)\n",
    "mlpclf2.fit(X_train_SpMJ, df['label'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.44      0.32      0.37       212\n",
      "       false       0.42      0.55      0.48       249\n",
      "   half-true       0.43      0.40      0.42       265\n",
      " mostly-true       0.36      0.63      0.46       241\n",
      "  pants-fire       0.62      0.49      0.55        92\n",
      "        true       0.81      0.17      0.28       208\n",
      "\n",
      "    accuracy                           0.43      1267\n",
      "   macro avg       0.51      0.43      0.42      1267\n",
      "weighted avg       0.49      0.43      0.42      1267\n",
      "\n",
      "0.4293606945540647\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_SpMJ.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.55      0.37      0.44       237\n",
      "       false       0.44      0.51      0.47       263\n",
      "   half-true       0.40      0.43      0.41       248\n",
      " mostly-true       0.37      0.63      0.47       251\n",
      "  pants-fire       0.61      0.44      0.51       116\n",
      "        true       0.80      0.20      0.31       169\n",
      "\n",
      "    accuracy                           0.45      1284\n",
      "   macro avg       0.53      0.43      0.44      1284\n",
      "weighted avg       0.50      0.45      0.44      1284\n",
      "\n",
      "0.4454828660436137\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_SpMJ.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,), random_state=1)\n",
    "mlpclf2.fit(X_train_SpMJ, train_blabels_df['label'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.69      0.94      0.80       794\n",
      "        true       0.75      0.30      0.43       473\n",
      "\n",
      "    accuracy                           0.70      1267\n",
      "   macro avg       0.72      0.62      0.62      1267\n",
      "weighted avg       0.71      0.70      0.66      1267\n",
      "\n",
      "0.7024467245461721\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_SpMJ.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.75      0.94      0.83       867\n",
      "        true       0.73      0.34      0.47       417\n",
      "\n",
      "    accuracy                           0.74      1284\n",
      "   macro avg       0.74      0.64      0.65      1284\n",
      "weighted avg       0.74      0.74      0.71      1284\n",
      "\n",
      "0.7445482866043613\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_SpMJ.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,), random_state=1)\n",
    "mlpclf2.fit(X_train_SpM, df['label'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.40      0.40      0.40       212\n",
      "       false       0.53      0.45      0.48       249\n",
      "   half-true       0.35      0.62      0.45       265\n",
      " mostly-true       0.44      0.48      0.46       241\n",
      "  pants-fire       0.62      0.54      0.58        92\n",
      "        true       0.92      0.16      0.27       208\n",
      "\n",
      "    accuracy                           0.44      1267\n",
      "   macro avg       0.54      0.44      0.44      1267\n",
      "weighted avg       0.52      0.44      0.43      1267\n",
      "\n",
      "0.4404104183109708\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_SpM.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.45      0.43      0.44       237\n",
      "       false       0.52      0.43      0.47       263\n",
      "   half-true       0.33      0.64      0.43       248\n",
      " mostly-true       0.47      0.47      0.47       251\n",
      "  pants-fire       0.62      0.45      0.52       116\n",
      "        true       0.97      0.18      0.31       169\n",
      "\n",
      "    accuracy                           0.45      1284\n",
      "   macro avg       0.56      0.43      0.44      1284\n",
      "weighted avg       0.53      0.45      0.44      1284\n",
      "\n",
      "0.4462616822429907\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_SpM.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,), random_state=1)\n",
    "mlpclf2.fit(X_train_SpM, train_blabels_df['label'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.69      0.95      0.80       794\n",
      "        true       0.77      0.30      0.43       473\n",
      "\n",
      "    accuracy                           0.70      1267\n",
      "   macro avg       0.73      0.62      0.62      1267\n",
      "weighted avg       0.72      0.70      0.66      1267\n",
      "\n",
      "0.7048145224940805\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_SpM.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.74      0.95      0.83       867\n",
      "        true       0.74      0.32      0.44       417\n",
      "\n",
      "    accuracy                           0.74      1284\n",
      "   macro avg       0.74      0.63      0.64      1284\n",
      "weighted avg       0.74      0.74      0.71      1284\n",
      "\n",
      "0.7422118380062306\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_SpM.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,), random_state=1)\n",
    "mlpclf2.fit(X_train_SJ, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.22      0.17      0.19       212\n",
      "       false       0.22      0.22      0.22       249\n",
      "   half-true       0.23      0.25      0.24       265\n",
      " mostly-true       0.21      0.23      0.22       241\n",
      "  pants-fire       0.15      0.11      0.13        92\n",
      "        true       0.20      0.23      0.21       208\n",
      "\n",
      "    accuracy                           0.21      1267\n",
      "   macro avg       0.21      0.20      0.20      1267\n",
      "weighted avg       0.21      0.21      0.21      1267\n",
      "\n",
      "0.21310181531176006\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_SJ.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.24      0.14      0.18       237\n",
      "       false       0.20      0.19      0.20       263\n",
      "   half-true       0.19      0.23      0.21       248\n",
      " mostly-true       0.27      0.31      0.29       251\n",
      "  pants-fire       0.17      0.12      0.14       116\n",
      "        true       0.18      0.24      0.20       169\n",
      "\n",
      "    accuracy                           0.21      1284\n",
      "   macro avg       0.21      0.21      0.20      1284\n",
      "weighted avg       0.22      0.21      0.21      1284\n",
      "\n",
      "0.21417445482866043\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_SJ.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,), random_state=1)\n",
    "mlpclf2.fit(X_train_SJ, train_blabels_df['label'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.64      0.68      0.65       794\n",
      "        true       0.39      0.35      0.37       473\n",
      "\n",
      "    accuracy                           0.55      1267\n",
      "   macro avg       0.51      0.51      0.51      1267\n",
      "weighted avg       0.54      0.55      0.55      1267\n",
      "\n",
      "0.55327545382794\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_SJ.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.70      0.72      0.71       867\n",
      "        true       0.38      0.36      0.37       417\n",
      "\n",
      "    accuracy                           0.60      1284\n",
      "   macro avg       0.54      0.54      0.54      1284\n",
      "weighted avg       0.60      0.60      0.60      1284\n",
      "\n",
      "0.6012461059190031\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_SJ.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,), random_state=1)\n",
    "mlpclf2.fit(X_train_S, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.19      0.17      0.18       212\n",
      "       false       0.27      0.26      0.26       249\n",
      "   half-true       0.25      0.25      0.25       265\n",
      " mostly-true       0.23      0.24      0.23       241\n",
      "  pants-fire       0.12      0.13      0.12        92\n",
      "        true       0.19      0.20      0.20       208\n",
      "\n",
      "    accuracy                           0.22      1267\n",
      "   macro avg       0.21      0.21      0.21      1267\n",
      "weighted avg       0.22      0.22      0.22      1267\n",
      "\n",
      "0.21941594317284924\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_S.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.22      0.18      0.19       237\n",
      "       false       0.26      0.26      0.26       263\n",
      "   half-true       0.20      0.23      0.21       248\n",
      " mostly-true       0.26      0.27      0.26       251\n",
      "  pants-fire       0.23      0.20      0.21       116\n",
      "        true       0.21      0.24      0.22       169\n",
      "\n",
      "    accuracy                           0.23      1284\n",
      "   macro avg       0.23      0.23      0.23      1284\n",
      "weighted avg       0.23      0.23      0.23      1284\n",
      "\n",
      "0.23052959501557632\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_S.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(30,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,), random_state=1)\n",
    "mlpclf2.fit(X_train_S, train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.65      0.65      0.65       794\n",
      "        true       0.41      0.40      0.40       473\n",
      "\n",
      "    accuracy                           0.56      1267\n",
      "   macro avg       0.53      0.53      0.53      1267\n",
      "weighted avg       0.56      0.56      0.56      1267\n",
      "\n",
      "0.5580110497237569\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_test_S.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.69      0.67      0.68       867\n",
      "        true       0.36      0.38      0.37       417\n",
      "\n",
      "    accuracy                           0.58      1284\n",
      "   macro avg       0.53      0.53      0.53      1284\n",
      "weighted avg       0.59      0.58      0.58      1284\n",
      "\n",
      "0.5794392523364486\n"
     ]
    }
   ],
   "source": [
    "predicted =mlpclf2.predict(X_val_S.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LinearSVC(random_state=0, tol=1e-5)\n",
    "# clf1 = SVC(gamma=1.7, kernel='rbf', random_state=42, probability=True)\n",
    "clf2 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "# clf2 = LogisticRegression(C=0.0001, random_state=42, n_jobs=-1)\n",
    "clf3 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf4 = GaussianNB()\n",
    "# clf4 = MultinomialNB(alpha=1.9)\n",
    "# clf5 = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('svm', clf1), ('lr', clf2),('rf', clf3), ('gnb', clf4)], voting='hard')\n",
    "# eclf_try = VotingClassifier(estimators=[('svm', clf1), ('lr', clf2), ('gnb', clf4)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# eclf_try = eclf_try.fit(X_train_SpMJ.toarray(), df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = eclf1.fit(X_train_SpM.toarray(), train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6503551696921863\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_SpM.toarray())\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6978193146417445\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_SpM.toarray())\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = eclf1.fit(X_train_SpM.toarray(), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3330702446724546\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_SpM.toarray())\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.352803738317757\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_SpM.toarray())\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpMJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "eclf1 = eclf1.fit(X_train_SpMJ.toarray(), train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.63      0.97      0.77       794\n",
      "        true       0.52      0.06      0.11       473\n",
      "\n",
      "    accuracy                           0.63      1267\n",
      "   macro avg       0.58      0.51      0.44      1267\n",
      "weighted avg       0.59      0.63      0.52      1267\n",
      "\n",
      "0.6282557221783741\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_SpMJ.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.69      0.96      0.81       867\n",
      "        true       0.59      0.11      0.18       417\n",
      "\n",
      "    accuracy                           0.69      1284\n",
      "   macro avg       0.64      0.53      0.49      1284\n",
      "weighted avg       0.66      0.69      0.60      1284\n",
      "\n",
      "0.6853582554517134\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_SpMJ.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "eclf1 = eclf1.fit(X_train_SpMJ.toarray(), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.23      0.25      0.24       212\n",
      "       false       0.29      0.37      0.32       249\n",
      "   half-true       0.30      0.44      0.36       265\n",
      " mostly-true       0.35      0.36      0.35       241\n",
      "  pants-fire       0.46      0.12      0.19        92\n",
      "        true       0.25      0.08      0.12       208\n",
      "\n",
      "    accuracy                           0.30      1267\n",
      "   macro avg       0.31      0.27      0.26      1267\n",
      "weighted avg       0.30      0.30      0.28      1267\n",
      "\n",
      "0.2959747434885556\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_SpMJ.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.32      0.31      0.31       237\n",
      "       false       0.36      0.42      0.39       263\n",
      "   half-true       0.34      0.55      0.42       248\n",
      " mostly-true       0.45      0.45      0.45       251\n",
      "  pants-fire       0.61      0.22      0.32       116\n",
      "        true       0.33      0.11      0.16       169\n",
      "\n",
      "    accuracy                           0.37      1284\n",
      "   macro avg       0.40      0.34      0.34      1284\n",
      "weighted avg       0.39      0.37      0.36      1284\n",
      "\n",
      "0.37149532710280375\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_SpMJ.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = eclf1.fit(X_train_SJ.toarray(), train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.63      0.92      0.75       794\n",
      "        true       0.38      0.08      0.13       473\n",
      "\n",
      "    accuracy                           0.61      1267\n",
      "   macro avg       0.50      0.50      0.44      1267\n",
      "weighted avg       0.53      0.61      0.52      1267\n",
      "\n",
      "0.6077348066298343\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_SJ.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.68      0.92      0.78       867\n",
      "        true       0.42      0.12      0.19       417\n",
      "\n",
      "    accuracy                           0.66      1284\n",
      "   macro avg       0.55      0.52      0.49      1284\n",
      "weighted avg       0.60      0.66      0.59      1284\n",
      "\n",
      "0.6596573208722741\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_SJ.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "eclf1 = eclf1.fit(X_train_SJ.toarray(), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.24      0.20      0.22       212\n",
      "       false       0.23      0.33      0.27       249\n",
      "   half-true       0.25      0.32      0.28       265\n",
      " mostly-true       0.21      0.23      0.22       241\n",
      "  pants-fire       0.75      0.03      0.06        92\n",
      "        true       0.18      0.11      0.14       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.31      0.20      0.20      1267\n",
      "weighted avg       0.26      0.23      0.22      1267\n",
      "\n",
      "0.22888713496448304\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_SJ.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.25      0.20      0.22       237\n",
      "       false       0.26      0.34      0.30       263\n",
      "   half-true       0.24      0.33      0.28       248\n",
      " mostly-true       0.28      0.29      0.29       251\n",
      "  pants-fire       0.30      0.03      0.05       116\n",
      "        true       0.17      0.14      0.15       169\n",
      "\n",
      "    accuracy                           0.25      1284\n",
      "   macro avg       0.25      0.22      0.21      1284\n",
      "weighted avg       0.25      0.25      0.23      1284\n",
      "\n",
      "0.24766355140186916\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_SJ.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "eclf1 = eclf1.fit(X_train_S.toarray(), train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.65      0.77      0.70       794\n",
      "        true       0.43      0.29      0.35       473\n",
      "\n",
      "    accuracy                           0.59      1267\n",
      "   macro avg       0.54      0.53      0.52      1267\n",
      "weighted avg       0.56      0.59      0.57      1267\n",
      "\n",
      "0.590370955011839\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_S.toarray())\n",
    "print(classification_report(test_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(test_blabels_df['label'])):\n",
    "    if test_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.71      0.81      0.75       867\n",
      "        true       0.44      0.31      0.36       417\n",
      "\n",
      "    accuracy                           0.65      1284\n",
      "   macro avg       0.57      0.56      0.56      1284\n",
      "weighted avg       0.62      0.65      0.63      1284\n",
      "\n",
      "0.6456386292834891\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_S.toarray())\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "eclf1 = eclf1.fit(X_train_S.toarray(), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.22      0.23      0.23       212\n",
      "       false       0.25      0.28      0.27       249\n",
      "   half-true       0.27      0.26      0.26       265\n",
      " mostly-true       0.23      0.23      0.23       241\n",
      "  pants-fire       0.15      0.11      0.13        92\n",
      "        true       0.21      0.21      0.21       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.22      0.22      0.22      1267\n",
      "weighted avg       0.23      0.23      0.23      1267\n",
      "\n",
      "0.23441199684293607\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_test_S.toarray())\n",
    "print(classification_report(df_test['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_test['label'])):\n",
    "    if df_test['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.24      0.23      0.24       237\n",
      "       false       0.27      0.32      0.29       263\n",
      "   half-true       0.22      0.21      0.21       248\n",
      " mostly-true       0.30      0.29      0.29       251\n",
      "  pants-fire       0.28      0.19      0.23       116\n",
      "        true       0.21      0.24      0.22       169\n",
      "\n",
      "    accuracy                           0.25      1284\n",
      "   macro avg       0.25      0.25      0.25      1284\n",
      "weighted avg       0.25      0.25      0.25      1284\n",
      "\n",
      "0.2523364485981308\n"
     ]
    }
   ],
   "source": [
    "predicted =eclf1.predict(X_val_S.toarray())\n",
    "print(classification_report(df_val['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(df_val['label'])):\n",
    "    if df_val['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import doc2vec\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'LIAR-PLUS/dataset/train2.tsv'\n",
    "filepath_test = 'LIAR-PLUS/dataset/test2.tsv'\n",
    "filepath_val = 'LIAR-PLUS/dataset/val2.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(filepath, usecols=[2,3,9,10,11,12,13,15], names=['label', 'statement','barely_true_count','false_count','half_true_count','mostly_true_count','pof_count','justification'], header=None, delimiter='\\t')\n",
    "df_test = pd.read_csv(filepath_test, usecols=[2,3,9,10,11,12,13,15], names=['label', 'statement','barely_true_count','false_count','half_true_count','mostly_true_count','pof_count','justification'], header=None, delimiter='\\t')\n",
    "df_val = pd.read_csv(filepath_val, usecols=[2,3,9,10,11,12,13,15], names=['label', 'statement','barely_true_count','false_count','half_true_count','mostly_true_count','pof_count','justification'], header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                 0\n",
       "statement             0\n",
       "barely_true_count     2\n",
       "false_count           2\n",
       "half_true_count       2\n",
       "mostly_true_count     2\n",
       "pof_count             2\n",
       "justification        84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[pd.notnull(df_train['barely_true_count'])]\n",
    "df_train = df_train[pd.notnull(df_train['justification'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                0\n",
       "statement            0\n",
       "barely_true_count    0\n",
       "false_count          0\n",
       "half_true_count      0\n",
       "mostly_true_count    0\n",
       "pof_count            0\n",
       "justification        9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[pd.notnull(df_test['justification'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                0\n",
       "statement            0\n",
       "barely_true_count    0\n",
       "false_count          0\n",
       "half_true_count      0\n",
       "mostly_true_count    0\n",
       "pof_count            0\n",
       "justification        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val[pd.notnull(df_val['justification'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_pro = df_train['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Label', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_df = pd.DataFrame(train_processed_SJ)\n",
    "train_processed_df.columns = [\"SJ\"]\n",
    "\n",
    "test_processed_df = pd.DataFrame(test_processed_SJ)\n",
    "test_processed_df.columns = [\"SJ\"]\n",
    "\n",
    "val_processed_df = pd.DataFrame(val_processed_SJ)\n",
    "val_processed_df.columns = [\"SJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# def cleanText(text):\n",
    "#     text = BeautifulSoup(text, \"lxml\").text\n",
    "#     text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "#     text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "#     text = text.lower()\n",
    "#     text = text.replace('x', '')\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['statement'] = df_train['statement'].apply(cleanText)\n",
    "df_train['statement'] = df_train['statement'].apply(preprocessing_pipeline)\n",
    "df_train['statement'] = df_train['statement'].apply(nlp)\n",
    "df_train['statement'] = df_train['statement'].apply(spacy_prepro)\n",
    "df_train['statement'] = df_train['statement'].apply(' '.join)\n",
    "\n",
    "# df_test['statement'] = df_test['statement'].apply(cleanText)\n",
    "df_test['statement'] = df_test['statement'].apply(preprocessing_pipeline)\n",
    "df_test['statement'] = df_test['statement'].apply(nlp)\n",
    "df_test['statement'] = df_test['statement'].apply(spacy_prepro)\n",
    "df_test['statement'] = df_test['statement'].apply(' '.join)\n",
    "\n",
    "# df_val['statement'] = df_val['statement'].apply(cleanText)\n",
    "df_val['statement'] = df_val['statement'].apply(preprocessing_pipeline)\n",
    "df_val['statement'] = df_val['statement'].apply(nlp)\n",
    "df_val['statement'] = df_val['statement'].apply(spacy_prepro)\n",
    "df_val['statement'] = df_val['statement'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the complaint narrative.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    flag=0\n",
    "    for i in range(len(corpus)):\n",
    "        label = label_type + '_' + str(i)\n",
    "        flag+=1\n",
    "        labeled.append(doc2vec.TaggedDocument(corpus[i].split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For S model\n",
    "X_train = label_sentences(df_train['statement'],'Train')\n",
    "# X_test = label_sentences(df_test['statement'],'Test')\n",
    "X_test = label_sentences(df_val['statement'],'Test') # Validation Set\n",
    "all_data = X_train + X_test\n",
    "\n",
    "# ## For SJ model\n",
    "# X_train = label_sentences(train_processed_df['SJ'],'Train')\n",
    "# X_test = label_sentences(test_processed_df['SJ'],'Test')\n",
    "# # X_test = label_sentences(val_processed_df['SJ'],'Test') # Validation Set\n",
    "# all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Bag of Words (DBOW) | Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11524/11524 [00:00<00:00, 2458678.43it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11524/11524 [00:00<00:00, 1610903.49it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1135427.75it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1040047.32it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1124413.41it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1043415.06it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1447160.46it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1161819.08it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1064956.03it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1189203.08it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1083165.10it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1054846.13it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1066883.55it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1078693.10it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1103567.65it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1052824.21it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1085549.10it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1117601.78it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1008284.85it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1183727.85it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 923307.72it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1031568.19it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1187450.17it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 955674.70it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1013251.98it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1064065.15it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 997815.06it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1141299.13it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1066412.78it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1198194.33it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1063948.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.7 s, sys: 4.07 s, total: 42.8 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flag=0\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    flag+=1\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha\n",
    "    flag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    flag=0\n",
    "    for i in range(0, corpus_size):\n",
    "        flag+=1\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        check=flag\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg =  LogisticRegression(random_state=0,solver='lbfgs',multi_class='multinomial').fit(train_vectors_dbow, train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.68      0.93      0.79       867\n",
      "        true       0.43      0.11      0.18       417\n",
      "\n",
      "    accuracy                           0.66      1284\n",
      "   macro avg       0.56      0.52      0.48      1284\n",
      "weighted avg       0.60      0.66      0.59      1284\n",
      "\n",
      "0.6635514018691588\n"
     ]
    }
   ],
   "source": [
    "predicted =logreg.predict(test_vectors_dbow)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = [25.93, 23.44, 44.04, 42.93]\n",
    "bars2 = [25.23, 24.76, 44.62, 44.54]\n",
    "# bars3 = [29, 3, 24, 25, 17]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "# r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='#87cefa', width=barWidth, edgecolor='white', label='test')\n",
    "plt.bar(r2, bars2, color='#ff8c00', width=barWidth, edgecolor='white', label='validation')\n",
    "# plt.bar(r3, bars3, color='#2d7f5e', width=barWidth, edgecolor='white', label='var3')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Multi-class Classification', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['S', 'SJ', 'S+M', 'S+MJ'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = [62.98, 62.35, 70.48, 70.24]\n",
    "bars2 = [67.60, 66.51, 74.22, 74.45]\n",
    "# bars3 = [29, 3, 24, 25, 17]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "# r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='#87cefa', width=barWidth, edgecolor='white', label='test')\n",
    "plt.bar(r2, bars2, color='#ff8c00', width=barWidth, edgecolor='white', label='validation')\n",
    "# plt.bar(r3, bars3, color='#2d7f5e', width=barWidth, edgecolor='white', label='var3')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Binary Classification', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['S', 'SJ', 'S+M', 'S+MJ'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SJ_sent = []\n",
    "for i in range(len(senti_train_df)):\n",
    "    posval = senti_train_df['pos_sent'][i]\n",
    "    negval = senti_train_df['neg_sent'][i]\n",
    "    textval = train_processed_S[i]\n",
    "    for j in range(int(posval)):\n",
    "        textval+=' _pos_sent_'\n",
    "    for j in range(int(negval)):\n",
    "        textval+=' _neg_sent_'\n",
    "    train_SJ_sent.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SJ_sent_emo = []\n",
    "for i in range(len(train_SJ_sent)):\n",
    "    textval = train_SJ_sent[i]\n",
    "    e1=emolex_train_df['e1'][i]\n",
    "    e2=emolex_train_df['e2'][i]\n",
    "    e3=emolex_train_df['e3'][i]\n",
    "    e4=emolex_train_df['e4'][i]\n",
    "    e5=emolex_train_df['e5'][i]\n",
    "    e6=emolex_train_df['e6'][i]\n",
    "    e7=emolex_train_df['e7'][i]\n",
    "    e8=emolex_train_df['e8'][i]\n",
    "    e9=emolex_train_df['e9'][i]\n",
    "    e10=emolex_train_df['e10'][i]\n",
    "    for j in range(int(e1)):\n",
    "        textval+=' _e1_feat_'\n",
    "    for j in range(int(e2)):\n",
    "        textval+=' _e2_feat_'\n",
    "    for j in range(int(e3)):\n",
    "        textval+=' _e3_feat_'\n",
    "    for j in range(int(e4)):\n",
    "        textval+=' _e4_feat_'\n",
    "    for j in range(int(e5)):\n",
    "        textval+=' _e5_feat_'\n",
    "    for j in range(int(e6)):\n",
    "        textval+=' _e6_feat_'\n",
    "    for j in range(int(e7)):\n",
    "        textval+=' _e7_feat_'\n",
    "    for j in range(int(e8)):\n",
    "        textval+=' _e8_feat_'\n",
    "    for j in range(int(e9)):\n",
    "        textval+=' _e9_feat_'\n",
    "    for j in range(int(e10)):\n",
    "        textval+=' _e10_feat_'\n",
    "    train_SJ_sent_emo.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SJ_sent_emo_hist = []\n",
    "for i in range(len(train_SJ_sent_emo)):\n",
    "    textval = train_SJ_sent_emo[i]\n",
    "    h1 = df['barely_true_count'][i]\n",
    "    h2 = df['false_count'][i]\n",
    "    h3 = df['half_true_count'][i]\n",
    "    h4 = df['mostly_true_count'][i]\n",
    "    h5 = df['pof_count'][i]\n",
    "    for j in range(int(h1)):\n",
    "        textval+=' _h1_feat_'\n",
    "    for j in range(int(h2)):\n",
    "        textval+=' _h2_feat_'\n",
    "    for j in range(int(h3)):\n",
    "        textval+=' _h3_feat_'\n",
    "    for j in range(int(h4)):\n",
    "        textval+=' _h4_feat_'\n",
    "    for j in range(int(h5)):\n",
    "        textval+=' _h5_feat_'\n",
    "    train_SJ_sent_emo_hist.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2vec test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SJ_sent = []\n",
    "for i in range(len(senti_test_df)):\n",
    "    posval = senti_test_df['pos_sent'][i]\n",
    "    negval = senti_test_df['neg_sent'][i]\n",
    "    textval = test_processed_S[i]\n",
    "    for j in range(int(posval)):\n",
    "        textval+=' _pos_sent_'\n",
    "    for j in range(int(negval)):\n",
    "        textval+=' _neg_sent_'\n",
    "    test_SJ_sent.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SJ_sent_emo = []\n",
    "for i in range(len(test_SJ_sent)):\n",
    "    textval = test_SJ_sent[i]\n",
    "    e1=emolex_test_df['e1'][i]\n",
    "    e2=emolex_test_df['e2'][i]\n",
    "    e3=emolex_test_df['e3'][i]\n",
    "    e4=emolex_test_df['e4'][i]\n",
    "    e5=emolex_test_df['e5'][i]\n",
    "    e6=emolex_test_df['e6'][i]\n",
    "    e7=emolex_test_df['e7'][i]\n",
    "    e8=emolex_test_df['e8'][i]\n",
    "    e9=emolex_test_df['e9'][i]\n",
    "    e10=emolex_test_df['e10'][i]\n",
    "    for j in range(int(e1)):\n",
    "        textval+=' _e1_feat_'\n",
    "    for j in range(int(e2)):\n",
    "        textval+=' _e2_feat_'\n",
    "    for j in range(int(e3)):\n",
    "        textval+=' _e3_feat_'\n",
    "    for j in range(int(e4)):\n",
    "        textval+=' _e4_feat_'\n",
    "    for j in range(int(e5)):\n",
    "        textval+=' _e5_feat_'\n",
    "    for j in range(int(e6)):\n",
    "        textval+=' _e6_feat_'\n",
    "    for j in range(int(e7)):\n",
    "        textval+=' _e7_feat_'\n",
    "    for j in range(int(e8)):\n",
    "        textval+=' _e8_feat_'\n",
    "    for j in range(int(e9)):\n",
    "        textval+=' _e9_feat_'\n",
    "    for j in range(int(e10)):\n",
    "        textval+=' _e10_feat_'\n",
    "    test_SJ_sent_emo.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SJ_sent_emo_hist = []\n",
    "for i in range(len(test_SJ_sent_emo)):\n",
    "    textval = test_SJ_sent_emo[i]\n",
    "    h1 = df_test['barely_true_count'][i]\n",
    "    h2 = df_test['false_count'][i]\n",
    "    h3 = df_test['half_true_count'][i]\n",
    "    h4 = df_test['mostly_true_count'][i]\n",
    "    h5 = df_test['pof_count'][i]\n",
    "    for j in range(int(h1)):\n",
    "        textval+=' _h1_feat_'\n",
    "    for j in range(int(h2)):\n",
    "        textval+=' _h2_feat_'\n",
    "    for j in range(int(h3)):\n",
    "        textval+=' _h3_feat_'\n",
    "    for j in range(int(h4)):\n",
    "        textval+=' _h4_feat_'\n",
    "    for j in range(int(h5)):\n",
    "        textval+=' _h5_feat_'\n",
    "    test_SJ_sent_emo_hist.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2vec val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_SJ_sent = []\n",
    "for i in range(len(senti_val_df)):\n",
    "    posval = senti_val_df['pos_sent'][i]\n",
    "    negval = senti_val_df['neg_sent'][i]\n",
    "    textval = val_processed_S[i]\n",
    "    for j in range(int(posval)):\n",
    "        textval+=' _pos_sent_'\n",
    "    for j in range(int(negval)):\n",
    "        textval+=' _neg_sent_'\n",
    "    val_SJ_sent.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_SJ_sent_emo = []\n",
    "for i in range(len(val_SJ_sent)):\n",
    "    textval = val_SJ_sent[i]\n",
    "    e1=emolex_val_df['e1'][i]\n",
    "    e2=emolex_val_df['e2'][i]\n",
    "    e3=emolex_val_df['e3'][i]\n",
    "    e4=emolex_val_df['e4'][i]\n",
    "    e5=emolex_val_df['e5'][i]\n",
    "    e6=emolex_val_df['e6'][i]\n",
    "    e7=emolex_val_df['e7'][i]\n",
    "    e8=emolex_val_df['e8'][i]\n",
    "    e9=emolex_val_df['e9'][i]\n",
    "    e10=emolex_val_df['e10'][i]\n",
    "    for j in range(int(e1)):\n",
    "        textval+=' _e1_feat_'\n",
    "    for j in range(int(e2)):\n",
    "        textval+=' _e2_feat_'\n",
    "    for j in range(int(e3)):\n",
    "        textval+=' _e3_feat_'\n",
    "    for j in range(int(e4)):\n",
    "        textval+=' _e4_feat_'\n",
    "    for j in range(int(e5)):\n",
    "        textval+=' _e5_feat_'\n",
    "    for j in range(int(e6)):\n",
    "        textval+=' _e6_feat_'\n",
    "    for j in range(int(e7)):\n",
    "        textval+=' _e7_feat_'\n",
    "    for j in range(int(e8)):\n",
    "        textval+=' _e8_feat_'\n",
    "    for j in range(int(e9)):\n",
    "        textval+=' _e9_feat_'\n",
    "    for j in range(int(e10)):\n",
    "        textval+=' _e10_feat_'\n",
    "    val_SJ_sent_emo.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_SJ_sent_emo_hist = []\n",
    "for i in range(len(val_SJ_sent_emo)):\n",
    "    textval = val_SJ_sent_emo[i]\n",
    "    h1 = df_val['barely_true_count'][i]\n",
    "    h2 = df_val['false_count'][i]\n",
    "    h3 = df_val['half_true_count'][i]\n",
    "    h4 = df_val['mostly_true_count'][i]\n",
    "    h5 = df_val['pof_count'][i]\n",
    "    for j in range(int(h1)):\n",
    "        textval+=' _h1_feat_'\n",
    "    for j in range(int(h2)):\n",
    "        textval+=' _h2_feat_'\n",
    "    for j in range(int(h3)):\n",
    "        textval+=' _h3_feat_'\n",
    "    for j in range(int(h4)):\n",
    "        textval+=' _h4_feat_'\n",
    "    for j in range(int(h5)):\n",
    "        textval+=' _h5_feat_'\n",
    "    val_SJ_sent_emo_hist.append(textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed_df = pd.DataFrame(train_SJ_sent_emo_hist)\n",
    "train_processed_df.columns = [\"SJ\"]\n",
    "\n",
    "test_processed_df = pd.DataFrame(test_SJ_sent_emo_hist)\n",
    "test_processed_df.columns = [\"SJ\"]\n",
    "\n",
    "val_processed_df = pd.DataFrame(val_SJ_sent_emo_hist)\n",
    "val_processed_df.columns = [\"SJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = label_sentences(train_processed_df['SJ'],'Train')\n",
    "# X_test = label_sentences(test_processed_df['SJ'],'Test') # Test Set\n",
    "X_test = label_sentences(val_processed_df['SJ'],'Test') # Validation Set\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11524/11524 [00:00<00:00, 3335529.59it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11524/11524 [00:00<00:00, 2474918.55it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1434320.29it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1118921.23it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1344361.11it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1069338.27it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1138556.98it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1111204.18it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1378365.97it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1339109.55it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1125749.01it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1293110.02it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1432959.57it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1106599.49it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1370005.37it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1210194.27it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1045581.88it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1161372.43it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1290107.28it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1193490.19it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1329898.45it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1083577.90it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1269305.65it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1286707.29it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1309611.99it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1463770.31it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1131864.91it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1120036.13it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1176753.73it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1195793.26it/s]\n",
      "100%|██████████| 11524/11524 [00:00<00:00, 1201918.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 s, sys: 4.39 s, total: 58.8 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flag=0\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    flag+=1\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha\n",
    "    flag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyash15097/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg =  LogisticRegression(random_state=0,solver='lbfgs',multi_class='multinomial').fit(train_vectors_dbow, train_blabels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.70      0.92      0.79       867\n",
      "        true       0.51      0.17      0.25       417\n",
      "\n",
      "    accuracy                           0.68      1284\n",
      "   macro avg       0.60      0.55      0.52      1284\n",
      "weighted avg       0.64      0.68      0.62      1284\n",
      "\n",
      "0.677570093457944\n"
     ]
    }
   ],
   "source": [
    "predicted =logreg.predict(test_vectors_dbow)\n",
    "print(classification_report(val_blabels_df['label'], predicted))\n",
    "count=0\n",
    "for i in range(len(val_blabels_df['label'])):\n",
    "    if val_blabels_df['label'][i]==predicted[i]:\n",
    "        count+=1\n",
    "print(count/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
